{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# IDC Cancer Classification Walkthrough\n",
        "\n",
        "This notebook walks through loading the IDC patch dataset, preparing splits by subject ID, creating loaders, initializing the ResNet18 transfer-learning model, and running a short training/evaluation cycle. It reuses the project modules in `src/`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project root: /Users/michaelcheng/Desktop/AI_projects/kaggle_cancer_classification\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import itertools\n",
        "\n",
        "# Add project root to sys.path for imports\n",
        "PROJECT_ROOT = Path(\"/Users/michaelcheng/Desktop/AI_projects/kaggle_cancer_classification\")\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.append(str(PROJECT_ROOT))\n",
        "\n",
        "print(\"Project root:\", PROJECT_ROOT)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import torch.optim as optim\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Build Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Tuple, List, Optional\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "class IDCDataset(Dataset):\n",
        "    \"\"\"Dataset for IDC cancer images with nested subject ID structure.\n",
        "    \n",
        "    Structure: {data_root}/{subject_id}/{0|1}/*.png\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data_root: str, subject_ids: List[str], transform: Optional[transforms.Compose] = None):\n",
        "        self.data_root = Path(data_root)\n",
        "        self.transform = transform\n",
        "\n",
        "        self.subject_ids = subject_ids\n",
        "        self.samples: List[Tuple[str, int]] = []\n",
        "        # collect all image paths and labels\n",
        "        for subject_id in self.subject_ids:\n",
        "            subject_dir = self.data_root / subject_id\n",
        "            # load negative class\n",
        "            neg_dir = subject_dir / \"0\"\n",
        "            neg_samples = 0\n",
        "            if neg_dir.exists():\n",
        "                for img_path in neg_dir.glob(\"*.png\"):\n",
        "                    self.samples.append((str(img_path), 0))\n",
        "                    neg_samples += 1\n",
        "            # load positive class\n",
        "            pos_dir = subject_dir / \"1\"\n",
        "            pos_samples = 0\n",
        "            if pos_dir.exists():\n",
        "                for img_path in pos_dir.glob(\"*.png\"):\n",
        "                    self.samples.append((str(img_path), 1))\n",
        "                    pos_samples += 1\n",
        "    \n",
        "    def __len__(self) -> int:\n",
        "        return len(self.samples)\n",
        "    \n",
        "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, int]:\n",
        "        \"\"\"Get image and label by index.\n",
        "        returns Tuple of (image tensor, label)\"\"\"\n",
        "\n",
        "        img_path, label = self.samples[idx]\n",
        "\n",
        "        # load image\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        # transform image\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# train / val / test split\n",
        "def split_subject_by_id(data_root: str, val_ratio: float = 0.25, test_ratio: float = 0.2, random_seed: int = 42) -> Tuple[List[str], List[str], List[str]]:\n",
        "    \"\"\"Split subjects by ID into train/val/test sets.\n",
        "    \n",
        "    Args:\n",
        "        data_root: Root directory containing subject ID folders\n",
        "        val_ratio: Proportion of subjects for validation\n",
        "        test_ratio: Proportion of subjects for testing\n",
        "        random_seed: Random seed for reproducibility\n",
        "    \n",
        "    Returns:\n",
        "        Tuple of (train_ids, val_ids, test_ids)\n",
        "    \"\"\"\n",
        "    subject_ids = os.listdir(data_root)\n",
        "    np.random.seed(random_seed)\n",
        "    np.random.shuffle(subject_ids)\n",
        "    n_total = len(subject_ids)\n",
        "    n_test = int(n_total * test_ratio)\n",
        "    n_val = int(n_total * val_ratio)\n",
        "    n_train = n_total - n_test - n_val\n",
        "    train_ids = subject_ids[:n_train]\n",
        "    val_ids = subject_ids[n_train:n_train + n_val]\n",
        "    test_ids = subject_ids[n_train + n_val:]\n",
        "    return train_ids, val_ids, test_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# image transforms\n",
        "def get_transform(image_size: int, mode: str) -> transforms.Compose:\n",
        "    \"\"\"Get image transforms based on mode.\n",
        "    \n",
        "    Args:\n",
        "        image_size: Size to resize images to\n",
        "        mode: \"train\" or \"val\"\n",
        "    \"\"\"\n",
        "    if mode == \"train\":\n",
        "        return transforms.Compose([\n",
        "            transforms.Resize((image_size, image_size)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean = [0.5, 0.5, 0.5], std = [0.5, 0.5, 0.5])\n",
        "        ])\n",
        "    else:\n",
        "        return transforms.Compose([\n",
        "            transforms.Resize((image_size, image_size)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean = [0.5, 0.5, 0.5], std = [0.5, 0.5, 0.5])\n",
        "        ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_dataloaders(data_root: str, batch_size: int, num_workers: int, val_ratio: float, test_ratio: float, image_size: int, random_seed: int) -> Tuple[DataLoader, DataLoader, DataLoader]:\n",
        "    \"\"\"Create train/val/test dataloaders with subject-based splitting.\n",
        "    \n",
        "    Args:\n",
        "        data_root: Root directory containing subject ID folders\n",
        "        batch_size: Batch size for all loaders\n",
        "        num_workers: Number of worker processes for data loading\n",
        "        val_ratio: Proportion of subjects for validation\n",
        "        test_ratio: Proportion of subjects for testing\n",
        "        image_size: Target image size\n",
        "        random_seed: Random seed for reproducibility\n",
        "    \n",
        "    Returns:\n",
        "        Tuple of (train_loader, val_loader, test_loader)\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    train_ids, val_ids, test_ids = split_subject_by_id(data_root=data_root, val_ratio=val_ratio, test_ratio=test_ratio, random_seed=random_seed)\n",
        "\n",
        "    # create datasets\n",
        "    train_dataset = IDCDataset(data_root=data_root, subject_ids=train_ids, transform=get_transform(image_size=image_size, mode=\"train\"))\n",
        "    val_dataset = IDCDataset(data_root=data_root, subject_ids=val_ids, transform=get_transform(image_size=image_size, mode=\"val\"))\n",
        "    test_dataset = IDCDataset(data_root=data_root, subject_ids=test_ids, transform=get_transform(image_size=image_size, mode=\"val\"))\n",
        "\n",
        "    # create dataloaders\n",
        "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "    val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "    test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Build Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "class cnn(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(cnn, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=3, stride=1, padding=1)\n",
        "        self.dropout = nn.Dropout2d(p=0.2)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        # 128 x 128 image with 2 pools of size 2 -> 128/2/2 = 32 -> 32 x 32 image dimension.\n",
        "        # created 24 output channels, so 24*32*32 is the flattened dimension to feed into the final layer\n",
        "        self.fc1 = nn.Linear(in_features=24*32*32, out_features=1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.pool(self.conv1(x)))\n",
        "        x = F.relu(self.pool(self.conv2(x)))\n",
        "        # add some dropout to prevent overfitting\n",
        "        x = F.relu(self.dropout(self.conv3(x)))\n",
        "        # flatten the output\n",
        "        x = x.view(-1, 24*32*32)\n",
        "        # dropout in training\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc1(x)\n",
        "        # sigmoid to get a probability output\n",
        "        x = F.sigmoid(x)\n",
        "        return x\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training and Testing Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(model, device, train_loader, val_loader, criterion, optimizer, epoch: int, max_training_batches: int = None):\n",
        "    # set model to training mode\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    print(\"Epoch: \", epoch)\n",
        "    if max_training_batches is not None:\n",
        "        train_loader = itertools.islice(train_loader, max_training_batches)\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # move data to device (need to target as a batch of 1)\n",
        "        data, target = data.to(device), target.to(device).float().unsqueeze(1)\n",
        "        # reset gradients        \n",
        "        optimizer.zero_grad()\n",
        "        # forward pass\n",
        "        output = model(data)\n",
        "        # compute loss\n",
        "        loss = criterion(output, target)\n",
        "        # keep running total\n",
        "        train_loss += loss.item()\n",
        "        # backpropogate\n",
        "        loss.backward()\n",
        "        # update weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # print loss after every 10 batches\n",
        "        if batch_idx % 100 == 0:\n",
        "            print(f\"Train Loss: {train_loss:.6f}\")\n",
        "    \n",
        "    # print average loss\n",
        "    avg_loss = train_loss / (batch_idx + 1)\n",
        "    print(f\"Average training loss: {avg_loss:.6f}\")\n",
        "    return avg_loss\n",
        "\n",
        "\n",
        "def test_model(model, device, test_loader, criterion):\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, target) in enumerate(test_loader):\n",
        "            data, target = data.to(device), target.to(device).float().unsqueeze(1)\n",
        "            # forward pass\n",
        "            output = model(data)\n",
        "            # comput loss\n",
        "            loss = criterion(output, target)\n",
        "            # keep running total\n",
        "            test_loss += loss.item()\n",
        "            # get predictions\n",
        "            pred = output.round()\n",
        "            # update correct count\n",
        "            correct += pred.eq(target).sum().item()\n",
        "            # print loss after every 10 batches\n",
        "            if batch_idx % 100 == 0:\n",
        "                print(f\"Test Loss: {test_loss:.6f}\")\n",
        "    \n",
        "    avg_loss = test_loss / (batch_idx + 1)\n",
        "    accuracy = 100. * correct / len(test_loader.dataset)\n",
        "    print(f\"Test Loss: {avg_loss:.6f}, Accuracy: {accuracy:.2f}%\")\n",
        "    return avg_loss, accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Optimizer and Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
        "model = cnn()\n",
        "model.to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
        "criterion = nn.BCELoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training and Testing Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_root = PROJECT_ROOT / \"IDC_regular_ps50_idx5\"\n",
        "batch_size = 32\n",
        "val_ratio = 0.25\n",
        "test_ratio = 0.2\n",
        "image_size = 128\n",
        "num_workers = 0\n",
        "random_seed = 42\n",
        "max_training_batches = None\n",
        "num_epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_loader, val_loader, test_loader = create_dataloaders(data_root=data_root, batch_size=batch_size, num_workers=num_workers, val_ratio=val_ratio, test_ratio=test_ratio, image_size=image_size, random_seed=random_seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1036"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:  0\n",
            "Train Loss: 0.288939\n",
            "Train Loss: 36.667025\n",
            "Train Loss: 71.860561\n",
            "Train Loss: 107.203399\n",
            "Train Loss: 142.334077\n",
            "Train Loss: 176.475295\n",
            "Train Loss: 209.308469\n",
            "Train Loss: 245.070798\n",
            "Train Loss: 278.745645\n",
            "Train Loss: 314.420453\n",
            "Train Loss: 349.221374\n",
            "Average training loss: 0.348081\n",
            "Epoch:  1\n",
            "Train Loss: 0.346234\n",
            "Train Loss: 33.181564\n",
            "Train Loss: 67.299998\n",
            "Train Loss: 100.308967\n",
            "Train Loss: 132.244472\n",
            "Train Loss: 164.865137\n",
            "Train Loss: 199.148097\n",
            "Train Loss: 231.902497\n",
            "Train Loss: 263.371959\n",
            "Train Loss: 295.505451\n",
            "Train Loss: 328.782639\n",
            "Average training loss: 0.328143\n",
            "Epoch:  2\n",
            "Train Loss: 0.431215\n",
            "Train Loss: 31.809772\n",
            "Train Loss: 62.718572\n",
            "Train Loss: 93.315312\n",
            "Train Loss: 124.400707\n",
            "Train Loss: 156.967931\n",
            "Train Loss: 189.714130\n",
            "Train Loss: 221.807181\n",
            "Train Loss: 252.358685\n",
            "Train Loss: 286.365653\n",
            "Train Loss: 318.604069\n",
            "Average training loss: 0.317712\n",
            "Epoch:  3\n",
            "Train Loss: 0.309925\n",
            "Train Loss: 30.228475\n",
            "Train Loss: 60.818413\n",
            "Train Loss: 91.180782\n",
            "Train Loss: 124.110787\n",
            "Train Loss: 155.356022\n",
            "Train Loss: 185.325772\n",
            "Train Loss: 215.538375\n",
            "Train Loss: 246.669261\n",
            "Train Loss: 278.196895\n",
            "Train Loss: 308.789126\n",
            "Average training loss: 0.308781\n",
            "Epoch:  4\n",
            "Train Loss: 0.154418\n",
            "Train Loss: 32.480102\n",
            "Train Loss: 64.478608\n",
            "Train Loss: 93.687157\n",
            "Train Loss: 124.168167\n",
            "Train Loss: 152.588203\n",
            "Train Loss: 182.817468\n",
            "Train Loss: 211.349605\n",
            "Train Loss: 240.636575\n",
            "Train Loss: 270.238416\n",
            "Train Loss: 300.728038\n",
            "Average training loss: 0.300901\n",
            "Epoch:  5\n",
            "Train Loss: 0.231268\n",
            "Train Loss: 29.199595\n",
            "Train Loss: 58.709777\n",
            "Train Loss: 89.065163\n",
            "Train Loss: 116.365722\n",
            "Train Loss: 144.117330\n",
            "Train Loss: 174.437440\n",
            "Train Loss: 202.695307\n",
            "Train Loss: 232.845273\n",
            "Train Loss: 262.747999\n",
            "Train Loss: 292.373884\n",
            "Average training loss: 0.292396\n",
            "Epoch:  6\n",
            "Train Loss: 0.222020\n",
            "Train Loss: 27.176949\n",
            "Train Loss: 55.589038\n",
            "Train Loss: 83.744820\n",
            "Train Loss: 113.258152\n",
            "Train Loss: 143.595952\n",
            "Train Loss: 172.783847\n",
            "Train Loss: 201.813627\n",
            "Train Loss: 230.670991\n",
            "Train Loss: 259.086947\n",
            "Train Loss: 287.340719\n",
            "Average training loss: 0.288221\n",
            "Epoch:  7\n",
            "Train Loss: 0.458657\n",
            "Train Loss: 26.404917\n",
            "Train Loss: 55.689423\n",
            "Train Loss: 83.273530\n",
            "Train Loss: 109.924687\n",
            "Train Loss: 137.343812\n",
            "Train Loss: 162.815939\n",
            "Train Loss: 192.863092\n",
            "Train Loss: 221.352100\n",
            "Train Loss: 250.617411\n",
            "Train Loss: 278.529436\n",
            "Average training loss: 0.278808\n",
            "Epoch:  8\n",
            "Train Loss: 0.355550\n",
            "Train Loss: 27.406940\n",
            "Train Loss: 53.388855\n",
            "Train Loss: 81.073302\n",
            "Train Loss: 108.196662\n",
            "Train Loss: 135.486209\n",
            "Train Loss: 162.758940\n",
            "Train Loss: 190.782258\n",
            "Train Loss: 215.892087\n",
            "Train Loss: 245.217456\n",
            "Train Loss: 271.839691\n",
            "Average training loss: 0.271698\n",
            "Epoch:  9\n",
            "Train Loss: 0.528851\n",
            "Train Loss: 26.716871\n",
            "Train Loss: 52.221976\n",
            "Train Loss: 77.349749\n",
            "Train Loss: 101.549898\n",
            "Train Loss: 127.054229\n",
            "Train Loss: 153.924076\n",
            "Train Loss: 180.289923\n",
            "Train Loss: 205.937618\n",
            "Train Loss: 233.572850\n",
            "Train Loss: 261.282143\n",
            "Average training loss: 0.262808\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs): \n",
        "    train_model(model, device, train_loader, val_loader, criterion, optimizer, epoch=epoch, max_training_batches=max_training_batches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 0.298149\n",
            "Test Loss: 44.461324\n",
            "Test Loss: 87.352998\n",
            "Test Loss: 128.189635\n",
            "Test Loss: 172.695911\n",
            "Test Loss: 214.246937\n",
            "Test Loss: 0.427492, Accuracy: 81.78%\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.4274923128356773, 81.78487144454105)"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_model(model, device, val_loader, criterion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [],
      "source": [
        "# test and evaluate model\n",
        "from sklearn.metrics import confusion_matrix\n",
        "model.eval()\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "with torch.no_grad():\n",
        "    for batch_idx, (data, target) in enumerate(test_loader):\n",
        "        data, target = data.to(device), target.to(device).float().unsqueeze(1)\n",
        "        output = model(data)\n",
        "        pred = output.round()\n",
        "        true_labels.extend(target.cpu().numpy().flatten())\n",
        "        predicted_labels.extend(pred.cpu().numpy().flatten())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot the confusion matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "ConfusionMatrixDisplay.from_predictions(true_labels, predicted_labels, display_labels=[\"No IDC\", \"IDC\"], cmap=plt.cm.Blues, normalize=\"true\")\n",
        "\n",
        "# plt.xlabel(\"Predicted\")\n",
        "# plt.ylabel(\"Actual\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pytorch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
